{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Classification Problem**  "
      ],
      "metadata": {
        "id": "dNM48g66RTLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading and summarizing the wine dataset\n",
        "import pandas as pd\n",
        "# define the location of the dataset\n",
        "# load the dataset as a data frame\n",
        "df = pd.read_csv(\"data_0002.csv\", header=None)\n",
        "# retrieve the numpy array\n",
        "data = df.values\n",
        "# split the columns into input and output variables\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# summarize the shape of the loaded data\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "q4XquY6qRamf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "rH45BnH7SEzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # minimally prepare dataset\n",
        " X = X.astype('float')\n",
        " y = LabelEncoder().fit_transform(y.astype('str'))"
      ],
      "metadata": {
        "id": "l4MDbf39R1S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model\n",
        "def evaluate_model(X, y, model):\n",
        "\t# define the cross-validation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate model\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores"
      ],
      "metadata": {
        "id": "H84Bywi1SBI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "# evaluate the model\n",
        "scores = evaluate_model(X, y, model)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "id": "43lM_kNnS7va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Grid Search Approach to Data transformation***"
      ],
      "metadata": {
        "id": "rP2fHJAVT8fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from matplotlib import pyplot\n",
        " \n",
        " \n",
        "# get modeling pipelines to evaluate\n",
        "def get_pipelines(model):\n",
        " pipelines = list()\n",
        " # normalize\n",
        " p = Pipeline([('s',MinMaxScaler()), ('m',model)])\n",
        " pipelines.append(('norm', p))\n",
        " # standardize\n",
        " p = Pipeline([('s',StandardScaler()), ('m',model)])\n",
        " pipelines.append(('std', p))\n",
        " # quantile\n",
        " p = Pipeline([('s',QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m',model)])\n",
        " pipelines.append(('quan', p))\n",
        " # discretize\n",
        " p = Pipeline([('s',KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')), ('m',model)])\n",
        " pipelines.append(('kbins', p))\n",
        " # pca\n",
        " p = Pipeline([('s',PCA(n_components=7)), ('m',model)])\n",
        " pipelines.append(('pca', p))\n",
        " # svd\n",
        " p = Pipeline([('s',TruncatedSVD(n_components=7)), ('m',model)])\n",
        " pipelines.append(('svd', p))\n",
        " return pipelines\n",
        " \n",
        "\n",
        "pipelines = get_pipelines(model)\n",
        "# evaluate each pipeline\n",
        "results, names = list(), list()\n",
        "for name, pipeline in pipelines:\n",
        " # evaluate\n",
        " scores = evaluate_model(X, y, pipeline)\n",
        " # summarize\n",
        " print('>%s: %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        " # store\n",
        " results.append(scores)\n",
        " names.append(name)\n",
        "# plot the result\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "q8WcP-tATmq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Grid Search Approach to Missing Data Handling***"
      ],
      "metadata": {
        "id": "54l4_Q-YUVu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataframe = pd.read_csv(\"data_0003.csv\", header=None, na_values='?')\n",
        "# summarize the first few rows\n",
        "print(dataframe.head())\n",
        "# summarize the number of rows with missing values for each column\n",
        "for i in range(dataframe.shape[1]):\n",
        "\t# count number of rows with missing values\n",
        "\tn_miss = dataframe[[i]].isnull().sum()\n",
        "\tperc = n_miss / dataframe.shape[0] * 100\n",
        "\tprint('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
      ],
      "metadata": {
        "id": "Etn2OolWUdbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import isnan\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# print total missing\n",
        "print('Missing: %d' % sum(isnan(X).flatten()))\n",
        "# define imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "# fit on the dataset\n",
        "imputer.fit(X)\n",
        "# transform the dataset\n",
        "Xtrans = imputer.transform(X)\n",
        "# print total missing\n",
        "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
      ],
      "metadata": {
        "id": "cykYO9OSVuWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# define modeling pipeline\n",
        "model = RandomForestClassifier()\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
        "# define model evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "id": "gZZ_b1NGWCpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare statistical imputation strategies\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# evaluate each strategy on the dataset\n",
        "results = list()\n",
        "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
        "for s in strategies:\n",
        "\t# create the modeling pipeline\n",
        "\tpipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())])\n",
        "\t# evaluate the model\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\t# store results\n",
        "\tresults.append(scores)\n",
        "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "S3K5Gt_VW9P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the modeling pipeline\n",
        "pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m', RandomForestClassifier())])\n",
        "# fit the model\n",
        "pipeline.fit(X, y)\n",
        "# define new data\n",
        "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
        "# make a prediction\n",
        "yhat = pipeline.predict([row])\n",
        "# summarize prediction\n",
        "print('Predicted Class: %d' % yhat[0])"
      ],
      "metadata": {
        "id": "gfqDWkc-VlT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7_ymoDTXCkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}